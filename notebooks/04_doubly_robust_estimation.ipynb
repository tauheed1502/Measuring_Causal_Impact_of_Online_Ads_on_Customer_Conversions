{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Doubly Robust Estimation\n",
    "\n",
    "This notebook implements doubly robust estimation:\n",
    "- Propensity score modeling\n",
    "- Outcome regression modeling\n",
    "- AIPW estimation\n",
    "- Confidence intervals and significance testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import cross_val_score, train_test_split\n",
    "from sklearn.metrics import roc_auc_score, mean_squared_error\n",
    "from src.models.doubly_robust import doubly_robust_estimation, aipw_estimation\n",
    "from src.evaluation.causal_metrics import compute_ate, lift_calculation\n",
    "from scipy import stats\n",
    "\n",
    "# Load preprocessed data\n",
    "df = pd.read_csv('../data/processed/preprocessed_ad_data.csv')\n",
    "confounders = pd.read_csv('../data/processed/confounders.csv')['confounder'].tolist()\n",
    "\n",
    "print(f\"Loaded {len(df)} observations with {len(confounders)} confounders\")\n",
    "print(f\"Treatment distribution: {df['treatment'].value_counts().to_dict()}\")\n",
    "\n",
    "# Calculate naive estimate for comparison\n",
    "naive_ate = df[df['treatment']==1]['conversion'].mean() - df[df['treatment']==0]['conversion'].mean()\n",
    "true_ate = df['true_effect'].iloc[0]\n",
    "print(f\"Naive ATE: {naive_ate:.4f}\")\n",
    "print(f\"True ATE: {true_ate:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Doubly Robust Estimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run doubly robust estimation\n",
    "dr_results = doubly_robust_estimation(df, confounders)\n",
    "\n",
    "print(\"=== DOUBLY ROBUST ESTIMATION RESULTS ===\")\n",
    "print(f\"Estimated ATE: {dr_results['ate']:.4f}\")\n",
    "print(f\"Standard Error: {dr_results['ate_se']:.4f}\")\n",
    "print(f\"95% Confidence Interval: [{dr_results['ate_ci_lower']:.4f}, {dr_results['ate_ci_upper']:.4f}]\")\n",
    "print(f\"\")\n",
    "print(f\"Components:\")\n",
    "print(f\"  Direct Effect: {dr_results['direct_effect']:.4f}\")\n",
    "print(f\"  Treated Residual: {dr_results['treated_residual']:.4f}\")\n",
    "print(f\"  Control Residual: {dr_results['control_residual']:.4f}\")\n",
    "\n",
    "# Statistical significance\n",
    "t_stat = dr_results['ate'] / dr_results['ate_se']\n",
    "p_value = 2 * (1 - stats.norm.cdf(abs(t_stat)))\n",
    "print(f\"\\nStatistical Significance:\")\n",
    "print(f\"  t-statistic: {t_stat:.3f}\")\n",
    "print(f\"  p-value: {p_value:.6f}\")\n",
    "print(f\"  Significant at 5%: {'Yes' if p_value < 0.05 else 'No'}\")\n",
    "\n",
    "# Bias correction\n",
    "bias_correction = naive_ate - dr_results['ate']\n",
    "bias_pct = (bias_correction / naive_ate) * 100 if naive_ate != 0 else 0\n",
    "print(f\"\\nBias Correction:\")\n",
    "print(f\"  Bias magnitude: {bias_correction:.4f}\")\n",
    "print(f\"  Bias percentage: {bias_pct:.1f}%\")\n",
    "print(f\"  Direction: {'Overstatement' if bias_correction > 0 else 'Understatement'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Model Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validate component models\n",
    "X = df[confounders]\n",
    "T = df['treatment']\n",
    "Y = df['conversion']\n",
    "\n",
    "# Validate propensity model\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n",
    "\n",
    "propensity_model = LogisticRegression(random_state=42, max_iter=1000)\n",
    "ps_scores = cross_val_score(propensity_model, X, T, cv=5, scoring='roc_auc')\n",
    "\n",
    "print(\"=== MODEL VALIDATION ===\")\n",
    "print(f\"Propensity Model Performance:\")\n",
    "print(f\"  Cross-val AUC: {ps_scores.mean():.3f} ± {ps_scores.std():.3f}\")\n",
    "print(f\"  Individual folds: {[f'{score:.3f}' for score in ps_scores]}\")\n",
    "\n",
    "# Validate outcome models\n",
    "outcome_model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "\n",
    "# Control group outcome model\n",
    "control_indices = T == 0\n",
    "control_scores = cross_val_score(outcome_model, X[control_indices], Y[control_indices], cv=5, scoring='neg_mean_squared_error')\n",
    "\n",
    "# Treatment group outcome model  \n",
    "treated_indices = T == 1\n",
    "treated_scores = cross_val_score(outcome_model, X[treated_indices], Y[treated_indices], cv=5, scoring='neg_mean_squared_error')\n",
    "\n",
    "print(f\"\\nOutcome Model Performance:\")\n",
    "print(f\"  Control model RMSE: {np.sqrt(-control_scores.mean()):.4f} ± {np.sqrt(control_scores.std()):.4f}\")\n",
    "print(f\"  Treatment model RMSE: {np.sqrt(-treated_scores.mean()):.4f} ± {np.sqrt(treated_scores.std()):.4f}\")\n",
    "\n",
    "# Check model assumptions\n",
    "print(f\"\\n=== MODEL ASSUMPTIONS ===\")\n",
    "print(f\"Propensity scores range: [{dr_results['propensity_scores'].min():.3f}, {dr_results['propensity_scores'].max():.3f}]\")\n",
    "print(f\"Extreme propensity scores (<0.1 or >0.9): {((dr_results['propensity_scores'] < 0.1) | (dr_results['propensity_scores'] > 0.9)).sum()}\")\n",
    "print(f\"Overlap condition: {'✅ Good' if dr_results['propensity_scores'].min() > 0.01 and dr_results['propensity_scores'].max() < 0.99 else '⚠️ Concern'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Diagnostic Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create diagnostic visualizations\n",
    "fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
    "fig.suptitle('Doubly Robust Estimation Diagnostics', fontsize=16)\n",
    "\n",
    "# 1. Propensity score distribution\n",
    "treated_ps = dr_results['propensity_scores'][T == 1]\n",
    "control_ps = dr_results['propensity_scores'][T == 0]\n",
    "\n",
    "axes[0,0].hist(control_ps, bins=30, alpha=0.7, label='Control', color='blue', density=True)\n",
    "axes[0,0].hist(treated_ps, bins=30, alpha=0.7, label='Treated', color='red', density=True)\n",
    "axes[0,0].set_xlabel('Propensity Score')\n",
    "axes[0,0].set_ylabel('Density')\n",
    "axes[0,0].set_title('Propensity Score Distribution')\n",
    "axes[0,0].legend()\n",
    "\n",
    "# 2. Predicted outcomes vs actual\n",
    "axes[0,1].scatter(dr_results['mu0'], Y, alpha=0.6, label='μ₀(X)', color='blue')\n",
    "axes[0,1].scatter(dr_results['mu1'], Y, alpha=0.6, label='μ₁(X)', color='red')\n",
    "axes[0,1].plot([0, 1], [0, 1], 'k--', alpha=0.5)\n",
    "axes[0,1].set_xlabel('Predicted Outcome')\n",
    "axes[0,1].set_ylabel('Actual Outcome')\n",
    "axes[0,1].set_title('Outcome Model Predictions')\n",
    "axes[0,1].legend()\n",
    "\n",
    "# 3. Residuals analysis\n",
    "treated_residuals = Y[T == 1] - dr_results['mu1'][T == 1]\n",
    "control_residuals = Y[T == 0] - dr_results['mu0'][T == 0]\n",
    "\n",
    "axes[0,2].scatter(dr_results['mu1'][T == 1], treated_residuals, alpha=0.6, color='red', label='Treated')\n",
    "axes[0,2].scatter(dr_results['mu0'][T == 0], control_residuals, alpha=0.6, color='blue', label='Control')\n",
    "axes[0,2].axhline(y=0, color='black', linestyle='--', alpha=0.5)\n",
    "axes[0,2].set_xlabel('Predicted Outcome')\n",
    "axes[0,2].set_ylabel('Residuals')\n",
    "axes[0,2].set_title('Residual Analysis')\n",
    "axes[0,2].legend()\n",
    "\n",
    "# 4. Treatment effect by propensity quintiles\n",
    "ps_quintiles = pd.qcut(dr_results['propensity_scores'], q=5, labels=['Q1', 'Q2', 'Q3', 'Q4', 'Q5'])\n",
    "quintile_effects = []\n",
    "for q in ['Q1', 'Q2', 'Q3', 'Q4', 'Q5']:\n",
    "    mask = ps_quintiles == q\n",
    "    treated_mean = Y[(T == 1) & mask].mean() if ((T == 1) & mask).sum() > 0 else 0\n",
    "    control_mean = Y[(T == 0) & mask].mean() if ((T == 0) & mask).sum() > 0 else 0\n",
    "    quintile_effects.append(treated_mean - control_mean)\n",
    "\n",
    "axes[1,0].bar(['Q1', 'Q2', 'Q3', 'Q4', 'Q5'], quintile_effects, alpha=0.8, color='green')\n",
    "axes[1,0].axhline(y=dr_results['ate'], color='red', linestyle='--', label=f\"Overall ATE = {dr_results['ate']:.3f}\")\n",
    "axes[1,0].set_xlabel('Propensity Score Quintile')\n",
    "axes[1,0].set_ylabel('Treatment Effect')\n",
    "axes[1,0].set_title('Treatment Effect by Propensity Quintile')\n",
    "axes[1,0].legend()\n",
    "\n",
    "# 5. Confidence interval visualization\n",
    "methods = ['Naive', 'Doubly Robust', 'True Effect']\n",
    "estimates = [naive_ate, dr_results['ate'], true_ate]\n",
    "errors = [0, dr_results['ate_se'], 0]\n",
    "colors = ['red', 'blue', 'green']\n",
    "\n",
    "bars = axes[1,1].bar(methods, estimates, yerr=[0, errors[1], 0], capsize=5, color=colors, alpha=0.7)\n",
    "axes[1,1].set_ylabel('Treatment Effect')\n",
    "axes[1,1].set_title('Method Comparison')\n",
    "\n",
    "# Add value labels\n",
    "for bar, est in zip(bars, estimates):\n",
    "    axes[1,1].text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.001,\n",
    "                  f'{est:.4f}', ha='center', va='bottom')\n",
    "\n",
    "# 6. Bootstrap confidence interval\n",
    "n_bootstrap = 1000\n",
    "bootstrap_ates = []\n",
    "\n",
    "np.random.seed(42)\n",
    "for _ in range(n_bootstrap):\n",
    "    # Bootstrap sample\n",
    "    idx = np.random.choice(len(df), size=len(df), replace=True)\n",
    "    df_boot = df.iloc[idx]\n",
    "    \n",
    "    try:\n",
    "        dr_boot = doubly_robust_estimation(df_boot, confounders)\n",
    "        bootstrap_ates.append(dr_boot['ate'])\n",
    "    except:\n",
    "        continue\n",
    "\n",
    "if bootstrap_ates:\n",
    "    axes[1,2].hist(bootstrap_ates, bins=30, alpha=0.7, color='purple', density=True)\n",
    "    axes[1,2].axvline(dr_results['ate'], color='red', linestyle='-', linewidth=2, label='Point Estimate')\n",
    "    axes[1,2].axvline(np.percentile(bootstrap_ates, 2.5), color='red', linestyle='--', alpha=0.7, label='95% CI')\n",
    "    axes[1,2].axvline(np.percentile(bootstrap_ates, 97.5), color='red', linestyle='--', alpha=0.7)\n",
    "    axes[1,2].set_xlabel('Bootstrap ATE Estimates')\n",
    "    axes[1,2].set_ylabel('Density')\n",
    "    axes[1,2].set_title('Bootstrap Distribution')\n",
    "    axes[1,2].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Business Impact Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate business metrics\n",
    "treated_outcomes = df[df['treatment']==1]['conversion']\n",
    "control_outcomes = df[df['treatment']==0]['conversion']\n",
    "\n",
    "lift_metrics = lift_calculation(treated_outcomes, control_outcomes)\n",
    "ate_metrics = compute_ate(treated_outcomes, control_outcomes)\n",
    "\n",
    "print(\"=== BUSINESS IMPACT ANALYSIS ===\")\n",
    "print(f\"\\n📊 Conversion Rates:\")\n",
    "print(f\"  Control Group: {lift_metrics['control_rate']:.3f} ({lift_metrics['control_rate']*100:.1f}%)\")\n",
    "print(f\"  Treatment Group: {lift_metrics['treated_rate']:.3f} ({lift_metrics['treated_rate']*100:.1f}%)\")\n",
    "\n",
    "print(f\"\\n📈 Lift Metrics:\")\n",
    "print(f\"  Absolute Lift (DR): {dr_results['ate']:.4f}\")\n",
    "print(f\"  Relative Lift (DR): {(dr_results['ate'] / lift_metrics['control_rate'] * 100):.1f}%\")\n",
    "print(f\"  Incremental per 1000: {dr_results['ate'] * 1000:.1f} conversions\")\n",
    "\n",
    "print(f\"\\n💰 Financial Impact (Example):\")\n",
    "monthly_impressions = 1000000\n",
    "aov = 50  # Average order value\n",
    "incremental_conversions = dr_results['ate'] * monthly_impressions\n",
    "additional_revenue = incremental_conversions * aov\n",
    "\n",
    "print(f\"  Monthly Impressions: {monthly_impressions:,}\")\n",
    "print(f\"  Incremental Conversions: {incremental_conversions:,.0f}\")\n",
    "print(f\"  Additional Revenue: ${additional_revenue:,.0f} (assuming ${aov} AOV)\")\n",
    "\n",
    "print(f\"\\n🎯 Confidence & Significance:\")\n",
    "print(f\"  Statistical Significance: {'✅ Yes' if p_value < 0.05 else '❌ No'} (p = {p_value:.4f})\")\n",
    "print(f\"  95% Confidence Interval: [{dr_results['ate_ci_lower']:.4f}, {dr_results['ate_ci_upper']:.4f}]\")\n",
    "print(f\"  Effect Size: {'Large' if abs(dr_results['ate']) > 0.01 else 'Medium' if abs(dr_results['ate']) > 0.005 else 'Small'}\")\n",
    "\n",
    "# Save results\n",
    "results_summary = {\n",
    "    'method': 'doubly_robust',\n",
    "    'ate': dr_results['ate'],\n",
    "    'ate_se': dr_results['ate_se'],\n",
    "    'ate_ci_lower': dr_results['ate_ci_lower'],\n",
    "    'ate_ci_upper': dr_results['ate_ci_upper'],\n",
    "    'p_value': p_value,\n",
    "    'bias_correction': bias_correction,\n",
    "    'bias_correction_pct': bias_pct\n",
    "}\n",
    "\n",
    "import pickle\n",
    "with open('../results/doubly_robust_results.pkl', 'wb') as f:\n",
    "    pickle.dump(dr_results, f)\n",
    "\n",
    "print(\"\\n✅ Results saved to '../results/doubly_robust_results.pkl'\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3", 
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
